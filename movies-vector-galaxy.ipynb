{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Galaxy — Semantic Movie Exploration\n"
      ],
      "metadata": {
        "id": "pnincHSP9Qx6"
      },
      "id": "pnincHSP9Qx6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "44nRko-YlnTt"
      },
      "id": "44nRko-YlnTt"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sPua1H_WkOtI"
      },
      "id": "sPua1H_WkOtI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset"
      ],
      "metadata": {
        "id": "d-cOATc_lrA_"
      },
      "id": "d-cOATc_lrA_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a53505-0611-4333-b1d7-ea9ed59d3da8",
      "metadata": {
        "id": "70a53505-0611-4333-b1d7-ea9ed59d3da8"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "movies_path = kagglehub.dataset_download(\"alanvourch/tmdb-movies-daily-updates\")\n",
        "\n",
        "# animes_path = kagglehub.dataset_download(\"calebmwelsh/anilist-anime-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(movies_path)"
      ],
      "metadata": {
        "id": "ZvB9WBfAjkKP"
      },
      "id": "ZvB9WBfAjkKP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv(f\"{movies_path}/TMDB_all_movies.csv\")"
      ],
      "metadata": {
        "id": "bFEaWRFOtwvW"
      },
      "id": "bFEaWRFOtwvW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Dataset"
      ],
      "metadata": {
        "id": "O9kMMjInnsXW"
      },
      "id": "O9kMMjInnsXW"
    },
    {
      "cell_type": "code",
      "source": [
        "# download samble data to view in excel\n",
        "# sample_movies = movies_df.sample(n=100, random_state=42)\n",
        "# sample_movies.to_csv(\"movies_sample_100.csv\", index=False)"
      ],
      "metadata": {
        "id": "mvG9W51N0NQv"
      },
      "id": "mvG9W51N0NQv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", movies_df.shape)\n",
        "print(\"\\nColumns:\", movies_df.columns.tolist())\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "display(movies_df.head(3))\n",
        "print(\"\\nInfo:\")\n",
        "movies_df.info()\n",
        "print(\"\\nMissing values (%):\")\n",
        "print((movies_df.isnull().sum() / len(movies_df) * 100).round(2).sort_values(ascending=False))\n",
        "print(\"\\nBasic stats:\")\n",
        "display(movies_df.describe())"
      ],
      "metadata": {
        "id": "jdey-roQkVpk"
      },
      "id": "jdey-roQkVpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title, overview, genres, cast, director, year"
      ],
      "metadata": {
        "id": "rKBH5_5klmLz"
      },
      "id": "rKBH5_5klmLz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ast\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot 1: Number of movies released each year\n",
        "print(\"\\n--- Movies Released Each Year ---\")\n",
        "movies_df['release_year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').dt.year\n",
        "year_counts = movies_df['release_year'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.lineplot(x=year_counts.index, y=year_counts.values)\n",
        "plt.title('Number of Movies Released Each Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Movies from each original language\n",
        "# This plot tells most of the movies are in english so ignore this feature.\n",
        "print(\"\\n--- Movies by Original Language ---\")\n",
        "language_counts = movies_df['original_language'].value_counts().head(20) # Top 20 languages\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=language_counts.index, y=language_counts.values, hue=language_counts.index, palette='viridis', legend=False)\n",
        "plt.title('Top 20 Original Languages of Movies')\n",
        "plt.xlabel('Original Language')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6l9Qf8O_k0Ab"
      },
      "id": "6l9Qf8O_k0Ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of peoples voted\n",
        "# for 66% of data the count is 0\n",
        "zero_vote_count = movies_df[movies_df['vote_count'] == 0]\n",
        "print(f\"Number of movies with 0 vote count: {len(zero_vote_count)}\")\n",
        "\n",
        "total_movies = movies_df.shape[0]\n",
        "percentage_zero_votes = (len(zero_vote_count) / total_movies) * 100\n",
        "print(f\"Percentage of movies with 0 vote count: {percentage_zero_votes:.2f}%\")"
      ],
      "metadata": {
        "id": "UG1ye-8XpJQQ"
      },
      "id": "UG1ye-8XpJQQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean Data"
      ],
      "metadata": {
        "id": "4v-nV3IVKS3s"
      },
      "id": "4v-nV3IVKS3s"
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = [\n",
        "    'id', 'title', 'overview', 'genres', 'cast', 'director',\n",
        "    'release_date', 'poster_path', 'popularity'\n",
        "]\n",
        "\n",
        "df = movies_df[keep_cols].copy()\n",
        "df['year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year.astype('Int64')\n",
        "print(\"Shape after selecting columns:\", df.shape)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "8JYEJpYFlAp1"
      },
      "id": "8JYEJpYFlAp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handle missing values"
      ],
      "metadata": {
        "id": "PeL1EnqKO57x"
      },
      "id": "PeL1EnqKO57x"
    },
    {
      "cell_type": "code",
      "source": [
        "df['genres'] = df['genres'].fillna('Unknown')\n",
        "df['cast'] = df['cast'].fillna('')\n",
        "df['director'] = df['director'].fillna('Unknown')\n",
        "df['year'] = df['year'].fillna(0).astype(int)\n",
        "\n",
        "print(\"Missing values after filling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "SQtr1RAhO5kY"
      },
      "id": "SQtr1RAhO5kY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[\n",
        "    df['title'].notna() &\n",
        "    (df['title'].str.strip() != '') &\n",
        "    df['overview'].notna() &\n",
        "    (df['overview'] != '') &\n",
        "    (df['overview'].str.len() >= 20)\n",
        "].copy()\n",
        "\n",
        "print(\"Shape after dropping bad overview rows:\", df.shape)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "P1965Nh0pPQ0"
      },
      "id": "P1965Nh0pPQ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def get_top_5_cast(cast_value):\n",
        "    if not cast_value:  # empty string\n",
        "        return ''\n",
        "\n",
        "    try:\n",
        "        # Most TMDB dumps store cast as stringified list: \"['Tom Hanks', 'Meg Ryan', ...]\"\n",
        "        if isinstance(cast_value, str) and cast_value.startswith('['):\n",
        "            cast_list = ast.literal_eval(cast_value)\n",
        "            if isinstance(cast_list, list):\n",
        "                return ', '.join(str(name).strip() for name in cast_list[:5])\n",
        "\n",
        "        # If it's already comma-separated\n",
        "        elif ',' in cast_value:\n",
        "            cast_list = [name.strip() for name in cast_value.split(',')]\n",
        "            return ', '.join(cast_list[:5])\n",
        "\n",
        "        # Fallback – just keep short\n",
        "        return str(cast_value)[:150]\n",
        "\n",
        "    except Exception:\n",
        "        return ''\n",
        "\n",
        "\n",
        "df['cast_top5'] = df['cast'].apply(get_top_5_cast)\n",
        "print(\"Sample cast cleaning:\")\n",
        "display(df[['title', 'cast', 'cast_top5']].sample(8))"
      ],
      "metadata": {
        "id": "WcmRRkoypyir"
      },
      "id": "WcmRRkoypyir",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "W-N9n-Gt3TFL"
      },
      "id": "W-N9n-Gt3TFL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "current_year = datetime.now().year\n",
        "year_cutoff = current_year - 5\n",
        "\n",
        "# Filter movies from the last 5 years and update df\n",
        "df = df[df['year'] >= year_cutoff].copy()\n",
        "\n",
        "print(f\"Number of movies in the last 5 years (from {year_cutoff} to {current_year}): {df.shape[0]}\")\n",
        "print(\"Shape of the DataFrame with recent movies:\", df.shape)"
      ],
      "metadata": {
        "id": "3rVQGJcW2SB_"
      },
      "id": "3rVQGJcW2SB_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_text(row):\n",
        "    parts = []\n",
        "\n",
        "    parts.append(f\"Title: {row['title']}.\")\n",
        "\n",
        "    overview = row['overview'][:650].rstrip(\" .!?\")\n",
        "    parts.append(f\"Overview: {overview}.\")\n",
        "\n",
        "    if row['genres'] != 'Unknown':\n",
        "        parts.append(f\"Genres: {row['genres']}.\")\n",
        "\n",
        "    if row['cast_top5']:\n",
        "        parts.append(f\"Cast: {row['cast_top5']}.\")\n",
        "\n",
        "    if row['director'] != 'Unknown':\n",
        "        parts.append(f\"Director: {row['director']}.\")\n",
        "\n",
        "    if row['year'] != 0:\n",
        "        parts.append(f\"Year: {row['year']}.\")\n",
        "\n",
        "    # Join as natural sentences + add E5 prefix\n",
        "    return \"passage: \" + \" \".join(parts)\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc=\"Building embedding text\")\n",
        "df['text_to_embed'] = df.progress_apply(build_text, axis=1)\n",
        "\n",
        "print(\"Sample text to embed:\")\n",
        "display(df[['title', 'text_to_embed']].sample(3))\n"
      ],
      "metadata": {
        "id": "5CzQa5pjSM5w"
      },
      "id": "5CzQa5pjSM5w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_to_embed'].iloc[0]"
      ],
      "metadata": {
        "id": "4J-XMYa7uqIj"
      },
      "id": "4J-XMYa7uqIj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "MSRcoOgaw93i"
      },
      "id": "MSRcoOgaw93i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned version\n",
        "df.to_parquet('movies_cleaned_for_embedding.parquet', index=False)"
      ],
      "metadata": {
        "id": "eLGSk5XxTDAn"
      },
      "id": "eLGSk5XxTDAn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings"
      ],
      "metadata": {
        "id": "8NJRJcpclPP6"
      },
      "id": "8NJRJcpclPP6"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "wdMiNr6xk-1p"
      },
      "id": "wdMiNr6xk-1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# CONFIG\n",
        "# ────────────────────────────────────────────────\n",
        "model_name = \"intfloat/multilingual-e5-large\"\n",
        "batch_size = 192\n",
        "checkpoint_every = 5000\n",
        "output_dir = \"./checkpoints\"\n",
        "\n",
        "embeddings_file = \"movie_embeddings.npy\"\n",
        "progress_file = \"embedding_progress.npy\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "full_embeddings_path = os.path.join(output_dir, embeddings_file)\n",
        "progress_path = os.path.join(output_dir, progress_file)\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# DATA\n",
        "# ────────────────────────────────────────────────\n",
        "texts = df[\"text_to_embed\"].tolist()\n",
        "total = len(texts)\n",
        "\n",
        "# Resume position\n",
        "if os.path.exists(progress_path):\n",
        "    start_idx = int(np.load(progress_path)[0])\n",
        "    print(f\"Resuming from index {start_idx} / {total}\")\n",
        "else:\n",
        "    start_idx = 0\n",
        "    print(\"Starting from beginning\")\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# MODEL\n",
        "# ────────────────────────────────────────────────\n",
        "print(f\"Loading {model_name}\")\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# speed + stability improvements\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Automatically detect embedding dimension\n",
        "embedding_dim = model.get_sentence_embedding_dimension()\n",
        "print(f\"Embedding dimension: {embedding_dim}\")\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# CREATE / LOAD MEMORY-MAPPED ARRAY\n",
        "# ────────────────────────────────────────────────\n",
        "if os.path.exists(full_embeddings_path):\n",
        "    embeddings = np.memmap(\n",
        "        full_embeddings_path,\n",
        "        dtype=\"float32\",\n",
        "        mode=\"r+\",\n",
        "        shape=(total, embedding_dim),\n",
        "    )\n",
        "    print(\"Loaded existing embedding memmap\")\n",
        "else:\n",
        "    embeddings = np.memmap(\n",
        "        full_embeddings_path,\n",
        "        dtype=\"float32\",\n",
        "        mode=\"w+\",\n",
        "        shape=(total, embedding_dim),\n",
        "    )\n",
        "    print(\"Created new embedding memmap\")\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# EMBEDDING LOOP (RESUMABLE)\n",
        "# ────────────────────────────────────────────────\n",
        "print(\"Starting / resuming embedding...\")\n",
        "\n",
        "save_interval_batches = max(1, checkpoint_every // batch_size)\n",
        "\n",
        "for step, i in enumerate(\n",
        "    tqdm(range(start_idx, total, batch_size), desc=\"Embedding batches\")\n",
        "):\n",
        "    end = min(i + batch_size, total)\n",
        "    chunk_texts = texts[i:end]\n",
        "\n",
        "    try:\n",
        "        chunk_emb = model.encode(\n",
        "            chunk_texts,\n",
        "            batch_size=batch_size,\n",
        "            show_progress_bar=False,\n",
        "            normalize_embeddings=True,\n",
        "            convert_to_numpy=True,\n",
        "        )\n",
        "\n",
        "        embeddings[i:end] = chunk_emb\n",
        "\n",
        "        # periodic checkpoint\n",
        "        if step % save_interval_batches == 0 or end == total:\n",
        "            embeddings.flush()  # write memmap to disk\n",
        "            np.save(progress_path, np.array([end]))\n",
        "            print(f\"Checkpoint saved at {end}/{total}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in batch {i}-{end}: {e}\")\n",
        "        print(\"Saving progress before exit...\")\n",
        "        embeddings.flush()\n",
        "        np.save(progress_path, np.array([i]))\n",
        "        raise e\n",
        "\n",
        "# Final save\n",
        "embeddings.flush()\n",
        "np.save(progress_path, np.array([total]))\n",
        "\n",
        "print(\"\\n✅ Embedding complete!\")\n",
        "print(f\"Saved embeddings at: {full_embeddings_path}\")\n",
        "print(f\"Final shape: ({total}, {embedding_dim})\")\n"
      ],
      "metadata": {
        "id": "2DhlTt5Bk-4y"
      },
      "id": "2DhlTt5Bk-4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisation"
      ],
      "metadata": {
        "id": "UKRG2Cb14F-x"
      },
      "id": "UKRG2Cb14F-x"
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r checkpoints.zip ./checkpoints\n",
        "from google.colab import files\n",
        "files.download('checkpoints.zip')"
      ],
      "metadata": {
        "id": "t49CWXXPk-8z"
      },
      "id": "t49CWXXPk-8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load embeddings\n",
        "embeddings_path = './checkpoints/movie_embeddings.npy'\n",
        "# Load as memory-mapped array, specifying dtype and shape\n",
        "# The shape is (total, embedding_dim) from the embedding cell's output\n",
        "total_embeddings = 210201  # Value of 'total' from previous embedding cell\n",
        "embedding_dimension = 1024 # Value of 'embedding_dim' from previous embedding cell\n",
        "embeddings = np.memmap(embeddings_path, dtype='float32', mode='r', shape=(total_embeddings, embedding_dimension))\n",
        "\n",
        "# Prepare metadata\n",
        "# Ensure 'df' is the filtered DataFrame used for embeddings\n",
        "# It should contain 'title', 'genres', 'cast_top5', 'director', 'year'\n",
        "metadata_df = df[['title', 'genres', 'cast_top5', 'director', 'year']].copy()\n",
        "\n",
        "# Create a single label for each movie by concatenating relevant metadata\n",
        "# This will be displayed when hovering over points in Projector\n",
        "metadata_df['label'] = metadata_df.apply(\n",
        "    lambda row: f\"{row['title']} ({row['year']}) - {row['genres']} - {row['cast_top5']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Save embeddings to TSV\n",
        "embeddings_tsv_path = 'embeddings.tsv'\n",
        "np.savetxt(embeddings_tsv_path, embeddings, delimiter='\\t')\n",
        "print(f\"Embeddings saved to {embeddings_tsv_path}\")\n",
        "\n",
        "# Save metadata to TSV\n",
        "metadata_tsv_path = 'metadata.tsv'\n",
        "metadata_df['label'].to_csv(metadata_tsv_path, sep='\\t', index=False, header=False)\n",
        "print(f\"Metadata saved to {metadata_tsv_path}\")\n",
        "\n",
        "print(\"\\nNow you can upload these two files to https://projector.tensorflow.org/\")"
      ],
      "metadata": {
        "id": "mYrxel-Rk-_m"
      },
      "id": "mYrxel-Rk-_m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip checkpoints.zip"
      ],
      "metadata": {
        "id": "eAQDoYhgk_Cy"
      },
      "id": "eAQDoYhgk_Cy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFDK4fM6k_Fd"
      },
      "id": "PFDK4fM6k_Fd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}